{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c850db74-f514-4cf9-b08a-4f08ed0cdcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Setup complete\n",
      "Features: C:\\Users\\VIJAY BHUSHAN SINGH\\depression_detection_project\\data\\features\n",
      "Output: C:\\Users\\VIJAY BHUSHAN SINGH\\depression_detection_project\\data\\processed\n",
      "Total sessions with labels: 189\n",
      "\n",
      "Label columns: ['Participant_ID', 'PHQ8_Binary', 'PHQ8_Score', 'Gender', 'PHQ8_NoInterest', 'PHQ8_Depressed', 'PHQ8_Sleep', 'PHQ8_Tired', 'PHQ8_Appetite', 'PHQ8_Failure', 'PHQ8_Concentrating', 'PHQ8_Moving', 'participant_ID']\n",
      "\n",
      "Sample labels:\n",
      "   Participant_ID  PHQ8_Binary  PHQ8_Score  Gender  PHQ8_NoInterest  \\\n",
      "0           303.0          0.0         0.0       0              0.0   \n",
      "1           304.0          0.0         6.0       0              0.0   \n",
      "2           305.0          0.0         7.0       1              0.0   \n",
      "3           310.0          0.0         4.0       1              1.0   \n",
      "4           312.0          0.0         2.0       1              0.0   \n",
      "\n",
      "   PHQ8_Depressed  PHQ8_Sleep  PHQ8_Tired  PHQ8_Appetite  PHQ8_Failure  \\\n",
      "0             0.0         0.0         0.0            0.0           0.0   \n",
      "1             1.0         1.0         2.0            2.0           0.0   \n",
      "2             1.0         1.0         2.0            2.0           1.0   \n",
      "3             1.0         0.0         0.0            0.0           1.0   \n",
      "4             0.0         1.0         1.0            0.0           0.0   \n",
      "\n",
      "   PHQ8_Concentrating  PHQ8_Moving  participant_ID  \n",
      "0                 0.0          0.0             NaN  \n",
      "1                 0.0          0.0             NaN  \n",
      "2                 0.0          0.0             NaN  \n",
      "3                 1.0          0.0             NaN  \n",
      "4                 0.0          0.0             NaN  \n",
      "\n",
      "✓ Audio: 26 rows, 69 columns\n",
      "✓ Text: 26 rows, 769 columns\n",
      "✓ Video: 26 rows, 76 columns\n",
      "\n",
      "============================================================\n",
      "ADDING FEATURE PREFIXES\n",
      "============================================================\n",
      "✓ Audio features renamed: 68 columns\n",
      "  Example: ['audio_mfcc_0_std', 'audio_mfcc_0_min', 'audio_mfcc_0_max']\n",
      "\n",
      "✓ Text features renamed: 768 columns\n",
      "  Example: ['text_feat_0', 'text_feat_1', 'text_feat_2']\n",
      "\n",
      "✓ Video features renamed: 75 columns\n",
      "  Example: ['video_AU01_r_std', 'video_AU01_r_max', 'video_AU02_r_mean']\n",
      "\n",
      "============================================================\n",
      "MERGING FEATURES\n",
      "============================================================\n",
      "Starting with audio: (26, 69)\n",
      "After merging text: (26, 837)\n",
      "After merging video: (26, 912)\n",
      "\n",
      "✓ Total features: 911\n",
      "\n",
      "============================================================\n",
      "ADDING PHQ-8 LABELS\n",
      "============================================================\n",
      "⚠ Warning: 8 sessions missing PHQ-8 scores\n",
      "Sessions without labels: [300, 301, 306, 308, 309, 311, 314, 323]\n",
      "Removed sessions without labels. Remaining: 18\n",
      "\n",
      "✓ Final dataset: 18 sessions\n",
      "✓ Total columns: 913\n",
      "\n",
      "PHQ-8 Score distribution:\n",
      "count    18.000000\n",
      "mean      6.500000\n",
      "std       4.718549\n",
      "min       0.000000\n",
      "25%       4.000000\n",
      "50%       5.500000\n",
      "75%       7.750000\n",
      "max      20.000000\n",
      "Name: PHQ8_Score, dtype: float64\n",
      "\n",
      "============================================================\n",
      "VERIFYING FEATURE PREFIXES\n",
      "============================================================\n",
      "✓ Audio features: 68\n",
      "✓ Text features: 768\n",
      "✓ Video features: 75\n",
      "\n",
      "✅ All features have correct prefixes!\n",
      "\n",
      "============================================================\n",
      "CREATING TRAIN/VAL/TEST SPLITS\n",
      "============================================================\n",
      "Sessions 300-325: 18\n",
      "⚠ Warning: Only 18 sessions available\n",
      "\n",
      "✓ Train set: 12 sessions (66.7%)\n",
      "✓ Val set: 3 sessions (16.7%)\n",
      "✓ Test set: 3 sessions (16.7%)\n",
      "\n",
      "Train session IDs: [304, 307, 312, 313, 316, 317, 318, 319, 321, 322, 324, 325]\n",
      "Val session IDs: [305, 310, 315]\n",
      "Test session IDs: [302, 303, 320]\n",
      "\n",
      "============================================================\n",
      "SAVING PROCESSED DATA\n",
      "============================================================\n",
      "✓ Saved: train_data.csv (12 rows, 913 cols)\n",
      "✓ Saved: val_data.csv (3 rows, 913 cols)\n",
      "✓ Saved: test_data.csv (3 rows, 913 cols)\n",
      "✓ Saved: full_dataset.csv (18 rows, 913 cols)\n",
      "\n",
      "============================================================\n",
      "FINAL VERIFICATION\n",
      "============================================================\n",
      "✓ Train: 12 samples\n",
      "✓ Val: 3 samples\n",
      "✓ Test: 3 samples\n",
      "\n",
      "Feature counts:\n",
      "  Audio: 68\n",
      "  Text: 768\n",
      "  Video: 75\n",
      "  Total: 911\n",
      "\n",
      "PHQ-8 Score ranges:\n",
      "  Train: 2.0 - 20.0\n",
      "  Val: 2.0 - 7.0\n",
      "  Test: 0.0 - 11.0\n",
      "\n",
      "============================================================\n",
      "✅✅✅ DATA MERGE SUCCESSFUL! ✅✅✅\n",
      "============================================================\n",
      "\n",
      "All features have correct prefixes!\n",
      "You can now re-run all modeling notebooks (10-21)\n",
      "\n",
      "Files saved to: C:\\Users\\VIJAY BHUSHAN SINGH\\depression_detection_project\\data\\processed\n",
      "\n",
      "Next step: Re-run Notebook 10 (HCMA training)\n"
     ]
    }
   ],
   "source": [
    "# ========== CELL 1: Setup ==========\n",
    "\"\"\"\n",
    "FIXED MERGE NOTEBOOK\n",
    "Properly merges audio, text, video features with correct prefixes\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROJECT_DIR = Path(r'C:\\Users\\VIJAY BHUSHAN SINGH\\depression_detection_project')\n",
    "FEATURES_DIR = PROJECT_DIR / 'data' / 'features'\n",
    "PROCESSED_DIR = PROJECT_DIR / 'data' / 'processed'\n",
    "RAW_DIR = PROJECT_DIR / 'data' / 'raw' / 'DAIC-WOZ'\n",
    "\n",
    "PROCESSED_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"✓ Setup complete\")\n",
    "print(f\"Features: {FEATURES_DIR}\")\n",
    "print(f\"Output: {PROCESSED_DIR}\")\n",
    "\n",
    "\n",
    "# ========== CELL 2: Load PHQ-8 Labels ==========\n",
    "\n",
    "# Load PHQ-8 scores\n",
    "train_split = pd.read_csv(RAW_DIR / 'train_split_Depression_AVEC2017.csv')\n",
    "dev_split = pd.read_csv(RAW_DIR / 'dev_split_Depression_AVEC2017.csv')\n",
    "test_split = pd.read_csv(RAW_DIR / 'test_split_Depression_AVEC2017.csv')\n",
    "\n",
    "# Combine all splits\n",
    "all_labels = pd.concat([train_split, dev_split, test_split], ignore_index=True)\n",
    "\n",
    "print(f\"Total sessions with labels: {len(all_labels)}\")\n",
    "print(f\"\\nLabel columns: {list(all_labels.columns)}\")\n",
    "print(f\"\\nSample labels:\\n{all_labels.head()}\")\n",
    "\n",
    "\n",
    "# ========== CELL 3: Load Feature Files ==========\n",
    "\n",
    "# Load audio features\n",
    "audio_df = pd.read_csv(FEATURES_DIR / 'audio_features.csv')\n",
    "print(f\"\\n✓ Audio: {len(audio_df)} rows, {len(audio_df.columns)} columns\")\n",
    "\n",
    "# Load text features  \n",
    "text_df = pd.read_csv(FEATURES_DIR / 'text_features.csv')\n",
    "print(f\"✓ Text: {len(text_df)} rows, {len(text_df.columns)} columns\")\n",
    "\n",
    "# Load video features\n",
    "video_df = pd.read_csv(FEATURES_DIR / 'video_features.csv')\n",
    "print(f\"✓ Video: {len(video_df)} rows, {len(video_df.columns)} columns\")\n",
    "\n",
    "\n",
    "# ========== CELL 4: Add Prefixes to Feature Names ==========\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ADDING FEATURE PREFIXES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Audio: Add 'audio_' prefix to all columns except session_id\n",
    "audio_cols = [col for col in audio_df.columns if col != 'session_id']\n",
    "audio_df = audio_df.rename(columns={col: f'audio_{col}' for col in audio_cols})\n",
    "print(f\"✓ Audio features renamed: {len(audio_cols)} columns\")\n",
    "print(f\"  Example: {list(audio_df.columns[1:4])}\")\n",
    "\n",
    "# Text: Add 'text_' prefix to all columns except session_id\n",
    "text_cols = [col for col in text_df.columns if col != 'session_id']\n",
    "text_df = text_df.rename(columns={col: f'text_{col}' for col in text_cols})\n",
    "print(f\"\\n✓ Text features renamed: {len(text_cols)} columns\")\n",
    "print(f\"  Example: {list(text_df.columns[1:4])}\")\n",
    "\n",
    "# Video: Add 'video_' prefix to all columns except session_id\n",
    "video_cols = [col for col in video_df.columns if col != 'session_id']\n",
    "video_df = video_df.rename(columns={col: f'video_{col}' for col in video_cols})\n",
    "print(f\"\\n✓ Video features renamed: {len(video_cols)} columns\")\n",
    "print(f\"  Example: {list(video_df.columns[1:4])}\")\n",
    "\n",
    "\n",
    "# ========== CELL 5: Merge All Features ==========\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MERGING FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Start with audio\n",
    "merged_df = audio_df.copy()\n",
    "print(f\"Starting with audio: {merged_df.shape}\")\n",
    "\n",
    "# Merge text\n",
    "merged_df = merged_df.merge(text_df, on='session_id', how='inner')\n",
    "print(f\"After merging text: {merged_df.shape}\")\n",
    "\n",
    "# Merge video\n",
    "merged_df = merged_df.merge(video_df, on='session_id', how='inner')\n",
    "print(f\"After merging video: {merged_df.shape}\")\n",
    "\n",
    "print(f\"\\n✓ Total features: {len(merged_df.columns) - 1}\")  # -1 for session_id\n",
    "\n",
    "\n",
    "# ========== CELL 6: Add PHQ-8 Labels ==========\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ADDING PHQ-8 LABELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Merge with labels (keep only sessions we have features for)\n",
    "merged_df = merged_df.merge(\n",
    "    all_labels[['Participant_ID', 'PHQ8_Score']], \n",
    "    left_on='session_id', \n",
    "    right_on='Participant_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop the duplicate ID column\n",
    "merged_df = merged_df.drop('Participant_ID', axis=1)\n",
    "\n",
    "# Check for missing labels\n",
    "missing_labels = merged_df['PHQ8_Score'].isna().sum()\n",
    "if missing_labels > 0:\n",
    "    print(f\"⚠ Warning: {missing_labels} sessions missing PHQ-8 scores\")\n",
    "    print(f\"Sessions without labels: {merged_df[merged_df['PHQ8_Score'].isna()]['session_id'].tolist()}\")\n",
    "    # Remove sessions without labels\n",
    "    merged_df = merged_df.dropna(subset=['PHQ8_Score'])\n",
    "    print(f\"Removed sessions without labels. Remaining: {len(merged_df)}\")\n",
    "\n",
    "print(f\"\\n✓ Final dataset: {len(merged_df)} sessions\")\n",
    "print(f\"✓ Total columns: {len(merged_df.columns)}\")\n",
    "print(f\"\\nPHQ-8 Score distribution:\")\n",
    "print(merged_df['PHQ8_Score'].describe())\n",
    "\n",
    "\n",
    "# ========== CELL 7: Verify Feature Prefixes ==========\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERIFYING FEATURE PREFIXES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "audio_features = [col for col in merged_df.columns if col.startswith('audio_')]\n",
    "text_features = [col for col in merged_df.columns if col.startswith('text_')]\n",
    "video_features = [col for col in merged_df.columns if col.startswith('video_')]\n",
    "\n",
    "print(f\"✓ Audio features: {len(audio_features)}\")\n",
    "print(f\"✓ Text features: {len(text_features)}\")\n",
    "print(f\"✓ Video features: {len(video_features)}\")\n",
    "\n",
    "if len(audio_features) == 0 or len(text_features) == 0 or len(video_features) == 0:\n",
    "    print(\"\\n❌ ERROR: Some feature types missing prefixes!\")\n",
    "else:\n",
    "    print(\"\\n✅ All features have correct prefixes!\")\n",
    "\n",
    "\n",
    "# ========== CELL 8: Create Train/Val/Test Splits ==========\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING TRAIN/VAL/TEST SPLITS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Filter to only our sessions (300-325)\n",
    "our_sessions = merged_df[merged_df['session_id'].between(300, 325)].copy()\n",
    "print(f\"Sessions 300-325: {len(our_sessions)}\")\n",
    "\n",
    "if len(our_sessions) < 20:\n",
    "    print(f\"⚠ Warning: Only {len(our_sessions)} sessions available\")\n",
    "\n",
    "# Split: 70% train, 15% val, 15% test\n",
    "train_df, temp_df = train_test_split(\n",
    "    our_sessions, \n",
    "    test_size=0.3, \n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Train set: {len(train_df)} sessions ({len(train_df)/len(our_sessions)*100:.1f}%)\")\n",
    "print(f\"✓ Val set: {len(val_df)} sessions ({len(val_df)/len(our_sessions)*100:.1f}%)\")\n",
    "print(f\"✓ Test set: {len(test_df)} sessions ({len(test_df)/len(our_sessions)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTrain session IDs: {sorted(train_df['session_id'].tolist())}\")\n",
    "print(f\"Val session IDs: {sorted(val_df['session_id'].tolist())}\")\n",
    "print(f\"Test session IDs: {sorted(test_df['session_id'].tolist())}\")\n",
    "\n",
    "\n",
    "# ========== CELL 9: Save Processed Data ==========\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING PROCESSED DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save splits\n",
    "train_df.to_csv(PROCESSED_DIR / 'train_data.csv', index=False)\n",
    "print(f\"✓ Saved: train_data.csv ({len(train_df)} rows, {len(train_df.columns)} cols)\")\n",
    "\n",
    "val_df.to_csv(PROCESSED_DIR / 'val_data.csv', index=False)\n",
    "print(f\"✓ Saved: val_data.csv ({len(val_df)} rows, {len(val_df.columns)} cols)\")\n",
    "\n",
    "test_df.to_csv(PROCESSED_DIR / 'test_data.csv', index=False)\n",
    "print(f\"✓ Saved: test_data.csv ({len(test_df)} rows, {len(test_df.columns)} cols)\")\n",
    "\n",
    "# Save full dataset\n",
    "our_sessions.to_csv(PROCESSED_DIR / 'full_dataset.csv', index=False)\n",
    "print(f\"✓ Saved: full_dataset.csv ({len(our_sessions)} rows, {len(our_sessions.columns)} cols)\")\n",
    "\n",
    "\n",
    "# ========== CELL 10: Final Verification ==========\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load back and verify\n",
    "train_check = pd.read_csv(PROCESSED_DIR / 'train_data.csv')\n",
    "val_check = pd.read_csv(PROCESSED_DIR / 'val_data.csv')\n",
    "test_check = pd.read_csv(PROCESSED_DIR / 'test_data.csv')\n",
    "\n",
    "# Count feature columns\n",
    "audio_cols = [c for c in train_check.columns if c.startswith('audio_')]\n",
    "text_cols = [c for c in train_check.columns if c.startswith('text_')]\n",
    "video_cols = [c for c in train_check.columns if c.startswith('video_')]\n",
    "\n",
    "print(f\"✓ Train: {len(train_check)} samples\")\n",
    "print(f\"✓ Val: {len(val_check)} samples\")\n",
    "print(f\"✓ Test: {len(test_check)} samples\")\n",
    "print(f\"\\nFeature counts:\")\n",
    "print(f\"  Audio: {len(audio_cols)}\")\n",
    "print(f\"  Text: {len(text_cols)}\")\n",
    "print(f\"  Video: {len(video_cols)}\")\n",
    "print(f\"  Total: {len(audio_cols) + len(text_cols) + len(video_cols)}\")\n",
    "\n",
    "# Check PHQ-8 scores\n",
    "print(f\"\\nPHQ-8 Score ranges:\")\n",
    "print(f\"  Train: {train_check['PHQ8_Score'].min():.1f} - {train_check['PHQ8_Score'].max():.1f}\")\n",
    "print(f\"  Val: {val_check['PHQ8_Score'].min():.1f} - {val_check['PHQ8_Score'].max():.1f}\")\n",
    "print(f\"  Test: {test_check['PHQ8_Score'].min():.1f} - {test_check['PHQ8_Score'].max():.1f}\")\n",
    "\n",
    "# Final success check\n",
    "if len(audio_cols) > 0 and len(text_cols) > 0 and len(video_cols) > 0:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✅✅✅ DATA MERGE SUCCESSFUL! ✅✅✅\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nAll features have correct prefixes!\")\n",
    "    print(\"You can now re-run all modeling notebooks (10-21)\")\n",
    "else:\n",
    "    print(\"\\n❌ ERROR: Feature prefixes still missing!\")\n",
    "    \n",
    "print(f\"\\nFiles saved to: {PROCESSED_DIR}\")\n",
    "print(\"\\nNext step: Re-run Notebook 10 (HCMA training)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311cf866-5d9a-427d-a5cc-42d7d73ea0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

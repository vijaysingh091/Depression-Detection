{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f356d3-8c62-408b-87ca-348ca1469e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries...\n",
      "✓ Libraries imported\n",
      "\n",
      "Loading features...\n",
      "✓ Audio: (26, 69)\n",
      "✓ Text: (26, 769)\n",
      "✓ Video: (26, 76)\n",
      "\n",
      "Loading PHQ-8 labels...\n",
      "✓ Labels shape: (107, 2)\n",
      "\n",
      "Merging all features (outer join)...\n",
      "✓ Final dataset: 16 sessions, 911 features\n",
      "\n",
      "Handling missing values...\n",
      "Missing values before: 0\n",
      "✓ Missing values after: 0\n",
      "\n",
      "Creating severity categories...\n",
      "✓ Severity categories created\n",
      "severity_name\n",
      "Mild        7\n",
      "Moderate    3\n",
      "None        5\n",
      "Severe      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Creating splits...\n",
      "⚠ Small dataset: stratification disabled\n",
      "✓ Splits created: Train=11, Val=2, Test=3\n",
      "\n",
      "Saving datasets...\n",
      "✓ Saved: train_data.csv\n",
      "✓ Saved: val_data.csv\n",
      "✓ Saved: test_data.csv\n",
      "\n",
      "Features by modality:\n",
      "  Audio: 68\n",
      "  Text: 0\n",
      "  Video: 72\n",
      "  Total: 911\n",
      "\n",
      "✅ MERGE + SPLIT COMPLETE!\n",
      "Total sessions: 16\n",
      "Train: 11, Val: 2, Test: 3\n",
      "Features: 911\n",
      "Files saved to: C:\\Users\\VIJAY BHUSHAN SINGH\\depression_detection_project\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FIXED MERGE + SPLIT NOTEBOOK - KEEP ALL SESSIONS\n",
    "\n",
    "SAVE AS: notebooks/exploratory/08_merge_all_features_FIXED.ipynb\n",
    "\"\"\"\n",
    "\n",
    "# ========== CELL 1: Import ==========\n",
    "print(\"Importing libraries...\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"✓ Libraries imported\")\n",
    "\n",
    "# ========== CELL 2: Load Features ==========\n",
    "print(\"\\nLoading features...\")\n",
    "\n",
    "FEATURES_DIR = Path(r'C:\\Users\\VIJAY BHUSHAN SINGH\\depression_detection_project\\data\\features')\n",
    "DATA_DIR = Path(r'C:\\Users\\VIJAY BHUSHAN SINGH\\depression_detection_project\\data\\raw\\DAIC-WOZ')\n",
    "PROCESSED_DIR = Path(r'C:\\Users\\VIJAY BHUSHAN SINGH\\depression_detection_project\\data\\processed')\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load all feature files\n",
    "audio_df = pd.read_csv(FEATURES_DIR / 'audio_features.csv')\n",
    "text_df = pd.read_csv(FEATURES_DIR / 'text_features.csv')\n",
    "video_df = pd.read_csv(FEATURES_DIR / 'video_features.csv')\n",
    "\n",
    "print(f\"✓ Audio: {audio_df.shape}\")\n",
    "print(f\"✓ Text: {text_df.shape}\")\n",
    "print(f\"✓ Video: {video_df.shape}\")\n",
    "\n",
    "# ========== CELL 3: Load Labels ==========\n",
    "print(\"\\nLoading PHQ-8 labels...\")\n",
    "labels_df = pd.read_csv(DATA_DIR / 'train_split_Depression_AVEC2017.csv')\n",
    "\n",
    "# Standardize session ID\n",
    "if 'Participant_ID' in labels_df.columns:\n",
    "    labels_df.rename(columns={'Participant_ID': 'session_id'}, inplace=True)\n",
    "elif 'participant_id' in labels_df.columns:\n",
    "    labels_df.rename(columns={'participant_id': 'session_id'}, inplace=True)\n",
    "\n",
    "# Keep only necessary columns\n",
    "if 'PHQ8_Score' in labels_df.columns:\n",
    "    labels_df = labels_df[['session_id', 'PHQ8_Score']]\n",
    "elif 'PHQ8_Total' in labels_df.columns:\n",
    "    labels_df.rename(columns={'PHQ8_Total': 'PHQ8_Score'}, inplace=True)\n",
    "    labels_df = labels_df[['session_id', 'PHQ8_Score']]\n",
    "\n",
    "print(f\"✓ Labels shape: {labels_df.shape}\")\n",
    "\n",
    "# ========== CELL 4: Merge Features (OUTER JOIN) ==========\n",
    "print(\"\\nMerging all features (outer join)...\")\n",
    "\n",
    "merged_df = audio_df.merge(text_df, on='session_id', how='outer', suffixes=('_audio', '_text'))\n",
    "merged_df = merged_df.merge(video_df, on='session_id', how='outer', suffixes=('', '_video'))\n",
    "\n",
    "# Merge with labels (inner join to keep only labeled sessions)\n",
    "final_df = merged_df.merge(labels_df, on='session_id', how='inner')\n",
    "\n",
    "print(f\"✓ Final dataset: {final_df.shape[0]} sessions, {final_df.shape[1]-2} features\")\n",
    "\n",
    "# ========== CELL 5: Handle Missing Values ==========\n",
    "print(\"\\nHandling missing values...\")\n",
    "\n",
    "missing_before = final_df.isnull().sum().sum()\n",
    "print(f\"Missing values before: {missing_before}\")\n",
    "\n",
    "# Fill all feature NaNs with column mean\n",
    "feature_cols = [c for c in final_df.columns if c not in ['session_id', 'PHQ8_Score']]\n",
    "for col in feature_cols:\n",
    "    final_df[col] = final_df[col].fillna(final_df[col].mean())\n",
    "\n",
    "missing_after = final_df.isnull().sum().sum()\n",
    "print(f\"✓ Missing values after: {missing_after}\")\n",
    "\n",
    "# ========== CELL 6: Create Severity Classes ==========\n",
    "print(\"\\nCreating severity categories...\")\n",
    "\n",
    "def categorize_severity(score):\n",
    "    if score <= 4:\n",
    "        return 0  # None\n",
    "    elif score <= 9:\n",
    "        return 1  # Mild\n",
    "    elif score <= 14:\n",
    "        return 2  # Moderate\n",
    "    else:\n",
    "        return 3  # Severe\n",
    "\n",
    "final_df['severity_class'] = final_df['PHQ8_Score'].apply(categorize_severity)\n",
    "severity_names = {0: 'None', 1: 'Mild', 2: 'Moderate', 3: 'Severe'}\n",
    "final_df['severity_name'] = final_df['severity_class'].map(severity_names)\n",
    "\n",
    "print(\"✓ Severity categories created\")\n",
    "print(final_df['severity_name'].value_counts().sort_index())\n",
    "\n",
    "# ========== CELL 7: Train/Val/Test Split ==========\n",
    "print(\"\\nCreating splits...\")\n",
    "\n",
    "X = final_df[feature_cols].values\n",
    "y_reg = final_df['PHQ8_Score'].values\n",
    "y_cls = final_df['severity_class'].values\n",
    "session_ids = final_df['session_id'].values\n",
    "\n",
    "# If dataset is small, stratify cannot be used reliably; check minimum class size\n",
    "min_class_count = final_df['severity_class'].value_counts().min()\n",
    "if min_class_count < 2:\n",
    "    stratify = None\n",
    "    print(\"⚠ Small dataset: stratification disabled\")\n",
    "else:\n",
    "    stratify = y_cls\n",
    "\n",
    "# 70/15/15 split\n",
    "X_train, X_temp, y_train_reg, y_temp_reg, y_train_cls, y_temp_cls, ids_train, ids_temp = train_test_split(\n",
    "    X, y_reg, y_cls, session_ids, test_size=0.3, random_state=42, stratify=stratify\n",
    ")\n",
    "X_val, X_test, y_val_reg, y_test_reg, y_val_cls, y_test_cls, ids_val, ids_test = train_test_split(\n",
    "    X_temp, y_temp_reg, y_temp_cls, ids_temp, test_size=0.5, random_state=42,\n",
    "    stratify=y_temp_cls if stratify is not None else None\n",
    ")\n",
    "\n",
    "print(f\"✓ Splits created: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}\")\n",
    "\n",
    "# ========== CELL 8: Save Datasets ==========\n",
    "print(\"\\nSaving datasets...\")\n",
    "\n",
    "final_df.to_csv(PROCESSED_DIR / 'complete_dataset.csv', index=False)\n",
    "\n",
    "def save_split(X_split, y_reg_split, y_cls_split, ids_split, filename):\n",
    "    df = pd.DataFrame(X_split, columns=feature_cols)\n",
    "    df['session_id'] = ids_split\n",
    "    df['PHQ8_Score'] = y_reg_split\n",
    "    df['severity_class'] = y_cls_split\n",
    "    df.to_csv(PROCESSED_DIR / filename, index=False)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "save_split(X_train, y_train_reg, y_train_cls, ids_train, 'train_data.csv')\n",
    "save_split(X_val, y_val_reg, y_val_cls, ids_val, 'val_data.csv')\n",
    "save_split(X_test, y_test_reg, y_test_cls, ids_test, 'test_data.csv')\n",
    "\n",
    "# ========== CELL 9: Feature Summary ==========\n",
    "audio_features = [c for c in feature_cols if any(x in c for x in ['mfcc','pitch','energy','spectral','zcr','rolloff','duration'])]\n",
    "text_features = [c for c in feature_cols if 'bert' in c.lower() or any(x in c.lower() for x in ['word','positive','negative','question'])]\n",
    "video_features = [c for c in feature_cols if 'AU' in c or 'gaze' in c.lower() or any(x in c for x in ['Tx','Ty','Tz','Rx','Ry','Rz'])]\n",
    "\n",
    "print(f\"\\nFeatures by modality:\")\n",
    "print(f\"  Audio: {len(audio_features)}\")\n",
    "print(f\"  Text: {len(text_features)}\")\n",
    "print(f\"  Video: {len(video_features)}\")\n",
    "print(f\"  Total: {len(feature_cols)}\")\n",
    "\n",
    "# ========== CELL 10: Final Summary ==========\n",
    "print(\"\\n✅ MERGE + SPLIT COMPLETE!\")\n",
    "print(f\"Total sessions: {len(final_df)}\")\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Files saved to: {PROCESSED_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd889d-ecc5-4be8-858b-e0fa8b4c2dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
